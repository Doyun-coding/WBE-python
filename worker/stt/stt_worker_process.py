import tempfile, os, requests
import whisper
import numpy as np
from openai import OpenAI
from scipy.io import wavfile
from worker.stt.util.stt_worker_util import record_triggered_by_voice
from worker.tts.tts_worker_process import run_tts_worker
from threading import Thread

# OpenAI api key
client = OpenAI()
# whisper large (base, medium, large í´ ìˆ˜ë¡ ì„±ëŠ¥ì´ ë†’ìŒ) ëª¨ë¸ ë¡œë”©
model = whisper.load_model("base")


def load_prompt_template(file_path: str) -> str:
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()


# whisper ì‚¬ìš©í•´ stt ê¸°ëŠ¥ í•¨ìˆ˜
def whisper_pipeline(summoner_id, audio_data):
    print(f"[ğŸ”Š Whisper] {summoner_id} ìŒì„± ë¶„ì„ ì‹œì‘")

    # ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ WAV íŒŒì¼ë¡œ ì„ì‹œ ì €ì¥
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
        wavfile.write(tmpfile.name, 16000, (audio_data * 32768).astype(np.int16))
        path = tmpfile.name

    # Whisper ì‚¬ìš©í•´ì„œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    result = model.transcribe(path)
    raw_text = result["text"]
    os.remove(path)

    print(f"[raw_text] : {raw_text}")

    # í…ìŠ¤íŠ¸ë¥¼ ê²Œì„ ìŠ¤íƒ€ì¼ë¡œ ì •ì œí•˜ëŠ” GPT í”„ë¡¬í”„íŠ¸
    prompt_template = load_prompt_template("prompt/champion_spell_prompt.txt")
    prompt = prompt_template.format(raw_text=raw_text)

    # GPT-4 API í˜¸ì¶œ
    gpt_response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=100
    )

    # ì •ì œëœ í…ìŠ¤íŠ¸ ê²°ê³¼ ì¶”ì¶œ
    final_text = gpt_response.choices[0].message.content.strip()
    print(f"[ğŸ¯ ê²°ê³¼] {summoner_id}: {final_text}")

    # ê²°ê³¼ë¥¼ Spring ì„œë²„ì— ì „ì†¡
    response = requests.post("http://localhost:8080/api/spell/flash", json={
        "summonerId": summoner_id,
        "finalText": final_text,
        "region": "KR"
    })

    if response.status_code == 201:
        print("âœ… Created: ì„œë²„ì—ì„œ ìì›ì„ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í•¨")

        run_tts_worker(summoner_id, response.text)
    else:
        print(f"âŒ ì‹¤íŒ¨ ë˜ëŠ” ë‹¤ë¥¸ ìƒíƒœ: {response.status_code} - {response.text}")


# Whisper ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤
def run_process_worker(summoner_id):
    print(f"ğŸ” {summoner_id} í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ")

    # ë‹¤ìŒ ìŒì„± ì¸ì‹ì„ ìœ„í•œ ìƒˆ í”„ë¡œì„¸ìŠ¤ë¥¼ ë¯¸ë¦¬ ìƒì„± (ì¬ê·€ ì•„ë‹˜)
    def spawn_next():
        from multiprocessing import Process

        print(f"{summoner_id} ë‹¤ìŒ í”„ë¡œì„¸ìŠ¤ ìƒì„±")
        Process(target=run_process_worker, args=(summoner_id,)).start()

    Thread(target=spawn_next, daemon=True).start()

    # ìŒì„± ì¸ì‹ ì‹œì‘
    audio_data = record_triggered_by_voice()

    if len(audio_data) > 0:
        whisper_pipeline(summoner_id, audio_data)

    print(f"[ğŸ›‘ ì¢…ë£Œ] {summoner_id} í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")

